{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, losses, util, InputExample, evaluation\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import pickle\n",
    "import warnings\n",
    "import math\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\tscore\tsentence1\tsentence2\n",
      "\n",
      "1\t4.979576587677002\tA man with a hard hat is dancing.\tA man wearing a hard hat is dancing.\n",
      "\n",
      "2\t4.829216480255127\tA young child is riding a horse.\tA child is riding a horse.\n",
      "\n",
      "3\t4.952564716339111\tA man is feeding a mouse to a snake.\tThe man is feeding a mouse to the snake.\n",
      "\n",
      "4\t4.33746862411499\tA woman is playing the guitar.\tA man is playing guitar.\n",
      "\n",
      "5\t4.576325416564941\tA woman is playing the flute.\tA man is playing a flute.\n",
      "\n",
      "6\t4.415567398071289\tA woman is cutting an onion.\tA man is cutting onions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/sample_test.csv\", delimiter='\\t', encoding=\"utf-8\").dropna()\n",
    "\n",
    "sentences1 = []\n",
    "sentences2 = []\n",
    "indexes = []\n",
    "\n",
    "def map_cos_to_zero_one(x):\n",
    "    mapped_value = (x + 1) / 2\n",
    "    return mapped_value\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    indexes.append(row[\"id\"])\n",
    "    sentences1.append(row[\"setence1\"])\n",
    "    sentences2.append(row[\"sentence2\"])\n",
    "\n",
    "with open('checkpoints/model_1C.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "predictions = []\n",
    "for i in range(len(cosine_scores)):\n",
    "    predictions.append(cosine_scores[i][i])\n",
    "transformed_predictions = [5 * map_cos_to_zero_one(value) for value in predictions]\n",
    "\n",
    "print(\"id\\tscore\\tsentence1\\tsentence2\\n\")\n",
    "with open('Data/sample_demo.csv', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"id\\tscore\\tsentence1\\tsentence2\\n\")\n",
    "    for i in range(len(predictions)):\n",
    "        print(f\"{indexes[i]}\\t{transformed_predictions[i]}\\t{sentences1[i]}\\t{sentences2[i]}\\n\")\n",
    "        f.write(f\"{indexes[i]}\\t{transformed_predictions[i]}\\t{sentences1[i]}\\t{sentences2[i]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
